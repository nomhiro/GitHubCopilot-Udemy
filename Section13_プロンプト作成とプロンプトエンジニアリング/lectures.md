# セクション13: プロンプト作成とプロンプトエンジニアリング（9%）

## 参照リソース
- [GitHub Copilot を使用したプロンプト エンジニアリングの概要 - Microsoft Learn](https://learn.microsoft.com/ja-jp/training/modules/introduction-prompt-engineering-with-github-copilot/)
- [GitHub Copilot ユーザー プロンプト プロセス フロー - Microsoft Learn](https://learn.microsoft.com/ja-jp/training/modules/introduction-prompt-engineering-with-github-copilot/3-github-copilot-user-prompt-process-flow)
- [GitHub Copilot データ - Microsoft Learn](https://learn.microsoft.com/ja-jp/training/modules/introduction-prompt-engineering-with-github-copilot/4-github-copilot-data)
- [GitHub Copilot 大規模言語モデル (LLM) - Microsoft Learn](https://learn.microsoft.com/ja-jp/training/modules/introduction-prompt-engineering-with-github-copilot/5-github-copilot-large-language-models)

---

## レクチャー1: プロンプトの基礎とコンテキスト決定
**時間目安: 10分**

### プロンプトエンジニアリングの4つのS原則

- **単一 (Single)**: 明確に定義された1つのタスクまたは質問を対象にする
- **具体的 (Specific)**: 指示を明確で詳細にする
- **短くする (Short)**: 具体的でありながら簡潔に
- **周囲環境 (Surround)**: わかりやすいファイル名と関連ファイルを開いたままにする

### ベストプラクティス
- 十分な明瞭さを提供する
- 詳細を含む十分なコンテキストを提供する
- 学習用の例を提供する
- アサートと反復（戦略的反復）

### 小テスト: GitHub Copilotとプロンプトの基礎

**Q1. GitHub Copilot とは何ですか?**
- A) コード リポジトリのためのプラットフォーム
- B) 機械学習を利用したモデル
- C) OpenAI を利用したコーディング用のアシスタント
- D) Web ホスティング用のサービス

<details>
<summary>解答</summary>
C) OpenAI を利用したコーディング用のアシスタント - GitHub CopilotはOpenAIのCodexモデルを活用したAIペアプログラマです。
</details>

**Q2. GitHub Copilot を効果的に利用するうえで、プロンプトはどのような役割を果たしますか?**
- A) インスタント バグ修正を生成します
- B) コード提案の品質が向上します
- C) コーディング プロセス全体が自動化されます
- D) リアルタイムのコラボレーションを実装します

<details>
<summary>解答</summary>
B) コード提案の品質が向上します - 適切なプロンプトを提供することで、Copilotからより関連性の高い正確なコード提案を受け取ることができます。
</details>

**Q3. 次の規則のうち、プロンプト エンジニアリングの 4 つの S の手法の原則であるものはどれですか?**
- A) コードの目標を簡潔に要約する
- B) 命令を明示的かつ詳細に指定する
- C) 効率的なコード提案のためにプロセスを効率化する
- D) 普遍的な理解のためにコーディング言語を簡略化する

<details>
<summary>解答</summary>
B) 命令を明示的かつ詳細に指定する - 4つのSの一つ「具体的 (Specific)」は、指示を明確で詳細にすることを意味します。
</details>

**Q4. Copilot はコードの提案を提供するために、コンテキストをどのように使用しますか?**
- A) 指定したプロンプト テキストのみが考慮されます
- B) ファイルの種類は考慮されますが、ファイルの内容は考慮されません
- C) コード エディターでは、周囲のコード、ファイルの種類、並列で開いているタブの内容が考慮されます
- D) インターネットからコンテキストをランダムに選択します

<details>
<summary>解答</summary>
C) コード エディターでは、周囲のコード、ファイルの種類、並列で開いているタブの内容が考慮されます - Copilotは現在のファイルだけでなく、IDE内の他の開いているファイルやタブも考慮して提案を生成します。
</details>

**Q5. 次の戦略のうち、GitHub Copilot でプロンプトの有効性の向上に役立つのはどれですか?**
- A) 詳細なコンテキスト情報を明確に提供する
- B) プロンプトを可能な限り汎用的なものにする
- C) プロンプトを長く詳細に保つ
- D) プロンプトでは例を避けて、Copilot の創造性を制限しないようにする

<details>
<summary>解答</summary>
A) 詳細なコンテキスト情報を明確に提供する - 十分な明瞭さと詳細を含むコンテキストを提供することで、より関連性の高い提案を得ることができます。
</details>

---

## レクチャー2: プロンプトの構成要素と言語オプション
**時間目安: 10分**

（内容を記述）

---

## レクチャー3: ゼロショット vs フューショットプロンプティング
**時間目安: 12分**

### 学習アプローチ

- **ゼロショット学習**: 具体的な例なしでコード生成
- **ワンショット学習**: 単一の例を提供してパターン認識を支援
- **少数ショット学習**: 複数の例でバランスの取れた予測

### ロールプロンプト

- セキュリティエキスパートの役割
- パフォーマンス最適化の役割
- テストスペシャリストの役割

---

## レクチャー4: チャット履歴の活用とベストプラクティス
**時間目安: 10分**

（内容を記述）

---

## レクチャー5: 【ハンズオン】効果的なプロンプトを書く
**時間目安: 15分**

（内容を記述）

---

## レクチャー6: プロンプトエンジニアリングの原則とプロセスフロー
**時間目安: 12分**

### GitHub Copilot ユーザー プロンプト プロセス フロー

#### インバウンド フロー

1. **安全なプロンプト送信とコンテキスト収集**
   - HTTPS経由での安全な送信
   - カーソル位置の前後のコード収集
   - ファイル名と種類の認識
   - 隣接する開いているタブの情報
   - プロジェクト構造とファイルパス
   - プログラミング言語とフレームワーク情報
   - Fill-in-the-Middle (FIM) 手法による前処理

2. **プロキシ フィルター**
   - Microsoft Azure テナントでホストされているプロキシサーバー
   - プロンプトのハッキングや操作の試みを阻止

3. **有害性フィルタリング**
   - ヘイトスピーチと不適切なコンテンツの検出・防止
   - 個人データ（名前、住所、ID番号）の除外

4. **LLMによるコード生成**
   - フィルター処理されたプロンプトがLLMモデルに渡される
   - コンテキストに基づいた関連性の高いコード提案を生成

#### アウトバウンド フロー

5. **後処理と応答の検証**
   - 有害性フィルターによる生成コンテンツの削除
   - コード品質チェック（XSS、SQLインジェクション等）
   - 一般公開コードとの一致チェック（オプション、150文字超の提案が対象）

6. **提案の提示とフィードバックループ**
   - 受け入れられた提案から知識を増加
   - 変更と拒否を通じた学習・改善

7. **後続のプロンプトに対して繰り返す**
   - 継続的な処理と累積フィードバックの適用
   - ユーザーの意図理解とコード生成機能の改善

### 小テスト: プロンプト プロセス フロー

**Q1. GitHub Copilotがユーザーのプロンプトを送信する際に使用されるプロトコルは？**
- A) HTTP
- B) HTTPS
- C) FTP
- D) WebSocket

<details>
<summary>解答</summary>
B) HTTPS - 安全かつ機密性の高い方法で送信され、機密情報が保護されます。
</details>

**Q2. インバウンドフローでコンテキスト収集時に使用される、先行と後続両方のコードコンテキストを考慮する手法は？**
- A) Context Window
- B) Token Embedding
- C) Fill-in-the-Middle (FIM)
- D) Attention Mechanism

<details>
<summary>解答</summary>
C) Fill-in-the-Middle (FIM) - この手法により、モデルの理解が拡大し、より正確で関連性の高いコード提案が可能になります。
</details>

**Q3. プロキシサーバーがホストされている場所はどこ？**
- A) AWS
- B) Google Cloud
- C) GitHub所有のMicrosoft Azureテナント
- D) オンプレミス

<details>
<summary>解答</summary>
C) GitHub所有のMicrosoft Azureテナント
</details>

**Q4. 一般公開されているコードとの一致チェックで、フィルターの対象となる提案の最小文字数は？**
- A) 50文字
- B) 100文字
- C) 150文字
- D) 200文字

<details>
<summary>解答</summary>
C) 150文字 - 管理者はこのフィルターをオプションで有効にでき、150文字を超える提案が既存の公開コードに類似している場合は返さないようにできます。
</details>

**Q5. 後処理でチェックされるセキュリティ脆弱性として正しい組み合わせは？**
- A) バッファオーバーフロー、メモリリーク
- B) クロスサイトスクリプティング（XSS）、SQLインジェクション
- C) DDoS攻撃、ブルートフォース
- D) フィッシング、マルウェア

<details>
<summary>解答</summary>
B) クロスサイトスクリプティング（XSS）、SQLインジェクション - コード品質チェックでこれらの一般的なバグや脆弱性がないか確認されます。
</details>

---

## レクチャー7: GitHub Copilotのデータ処理
**時間目安: 8分**

### コード提案のためのデータ処理
- コードエディター内のGitHub Copilotは、基本モデルをトレーニングする上でプロンプトを保持しない
- 提案を返したらプロンプトは破棄される
- GitHub Copilot Individualのサブスクライバーは、GitHubとのプロンプト共有をオプトアウト可能
- オプトアウトしない場合、プロンプトはGitHubの基本モデルの微調整に使用される

### GitHub Copilot Chat のためのデータ処理
- **書式設定**: 生成された応答を最適に表示、コードスニペットの強調表示、コードへの直接統合オプション
- **ユーザーエンゲージメント**: フォローアップ質問対応、説明リクエスト対応、チャット履歴によるコンテキスト保持
- **データ保有期間**: コードエディター外（CLI、Mobile、GitHub.com）では28日間保持

### サポートされるプロンプトの種類

| 種類 | 説明 | 例 |
|------|------|-----|
| 直接の質問 | コーディング概念、ライブラリ、トラブルシューティング | 「Pythonでクイックソートを実装するには？」 |
| コード関連の要求 | コード生成、変更、説明 | 「階乗を計算する関数を作成してください」 |
| 自由回答式クエリ | コーディング概念の調査、一般的ガイダンス | 「クリーンなコードのベストプラクティスとは？」 |
| コンテキストプロンプト | コードスニペット指定、カスタマイズ支援 | 「このコードの改善点を提案してください」 |

### コンテキストウィンドウの制限

| 機能 | コンテキストウィンドウ | 備考 |
|------|----------------------|------|
| 標準GitHub Copilot | 約200〜500行（最大数千トークン） | 実装とバージョンにより異なる |
| GitHub Copilot Chat | 4Kトークン | より広範なスコープでクエリを理解・応答 |

### 推奨事項
- 複雑な問題をより小さく焦点を絞ったクエリに分割
- 関連するコードスニペットを提供
- モデルの正確性と有用性を向上させる

### 小テスト: GitHub Copilot データ

**Q1. コードエディター内のGitHub Copilotで、提案を生成した後のプロンプトはどうなりますか？**
- A) 永続的に保存される
- B) 28日間保持される
- C) 破棄される
- D) 他のユーザーと共有される

<details>
<summary>解答</summary>
C) 破棄される - コードエディター内のGitHub Copilotは、提案を返した後にプロンプトを破棄します。
</details>

**Q2. GitHub Copilot Individualのサブスクライバーがプロンプト共有をオプトアウトしない場合、そのデータは何に使用されますか？**
- A) 広告のターゲティング
- B) GitHubの基本モデルの微調整
- C) 第三者への販売
- D) セキュリティ監査

<details>
<summary>解答</summary>
B) GitHubの基本モデルの微調整 - オプトアウトしない場合、共有されたプロンプトはGitHubの基本モデルを微調整するために使用されます。
</details>

**Q3. コードエディター外でCopilot Chatを使用した場合、プロンプトと提案のデータ保有期間は？**
- A) 7日間
- B) 14日間
- C) 28日間
- D) 90日間

<details>
<summary>解答</summary>
C) 28日間 - CLI、Mobile、GitHub.com上のCopilot Chatでは、プロンプト、提案、関連コンテキストを28日間保持します。
</details>

**Q4. GitHub Copilot Chatのコンテキストウィンドウのサイズは？**
- A) 1Kトークン
- B) 2Kトークン
- C) 4Kトークン
- D) 8Kトークン

<details>
<summary>解答</summary>
C) 4Kトークン - Copilot Chatは4Kトークンのコンテキストウィンドウで動作し、標準的なCopilotより広範なスコープを提供します。
</details>

**Q5. 標準的なGitHub Copilotのコンテキストウィンドウの範囲として正しいものは？**
- A) 約50〜100行
- B) 約200〜500行
- C) 約1000〜2000行
- D) 約5000〜10000行

<details>
<summary>解答</summary>
B) 約200〜500行 - GitHub Copilotのコンテキストウィンドウの範囲は通常約200〜500行のコード、または最大数千のトークンです。
</details>

**Q6. GitHub Copilot は個人データをどのように処理しますか?**
- A) 将来の参照のためにすべての個人データが保存されます
- B) コラボレーション プロジェクトのために、個人データを他のユーザーと共有します
- C) 個人データを暗号化します
- D) ユーザーのプライバシーを保護するために、個人データを積極的に除外します

<details>
<summary>解答</summary>
D) ユーザーのプライバシーを保護するために、個人データを積極的に除外します - 有害性フィルタリングにより、個人データ（名前、住所、ID番号など）が積極的に除外されます。
</details>

---

## レクチャー8: 大規模言語モデル（LLM）の基礎
**時間目安: 10分**

GitHub Copilotは、コードをシームレスに記述するのに役立つ大規模言語モデル（LLM）を利用しています。

### LLMとは

大規模言語モデル（LLM）は、人間の言語を理解、生成、操作するために設計およびトレーニングされた人工知能モデルです。

- **トレーニングデータの量**: さまざまなソースからの膨大な量のテキストにさらされ、言語、コンテキスト、複雑性に関する幅広い理解を獲得
- **コンテキストの理解**: コンテキストに関連する一貫性のあるテキストを生成するのに優れ、文や段落の完成、ドキュメント全体の生成が可能
- **機械学習とAIの統合**: 数百万から数十億ものパラメーターを持つニューラルネットワークで構成
- **汎用性**: 特定の種類のテキストや言語に限定されず、特殊なタスクを実行するように調整・微調整が可能

### GitHub CopilotでのLLMの役割

- LLMを利用してコンテキストに対応したコード提案を提供
- 現在のファイルだけでなく、IDE内の他の開いているファイルやタブも考慮
- 正確で関連するコード補完を生成し、生産性を向上

### LLMの微調整

微調整は、事前トレーニング済みのLLMを特定のタスクや分野に向けて調整するプロセスです。

- **ソースモデル**: 大規模な事前トレーニング済みデータセットから得られた知識とパラメーター
- **ターゲットデータセット**: タスク固有の小さなデータセット
- 特定のタスクに合わせてLLMを調整し、パフォーマンスを向上

### LoRA（低ランク適応）による微調整

従来の完全な微調整は、ニューラルネットワークのすべての部分をトレーニングするため、低速でリソース集約的です。LoRA（Low-Rank Adaptation）は効率的な代替手段です。

- **仕組み**: 事前トレーニング済みモデルの各レイヤーに小さなトレーニング可能なパーツを追加
- **利点**: 元のモデルは変更せず、時間とリソースを節約
- **性能**: アダプターやプレフィックスチューニングなどの他の適応方法より優れた結果
- **用途**: GitHub Copilotの特定のコーディング要件に合わせてLLMを向上させるためのスマートな方法

### 小テスト: 大規模言語モデル（LLM）

**Q1. LLMのトレーニングに使用されるパラメーター数の規模として正しいものは？**
- A) 数百〜数千
- B) 数万〜数十万
- C) 数百万〜数十億
- D) 数兆以上

<details>
<summary>解答</summary>
C) 数百万〜数十億 - LLMは、テキストを効果的に理解して予測するためにトレーニングプロセス中に微調整される数百万から数十億ものパラメーターを持つニューラルネットワークです。
</details>

**Q2. GitHub CopilotのLLMがコード提案時に考慮する範囲は？**
- A) 現在のファイルのみ
- B) 現在のファイルとIDE内の他の開いているファイル/タブ
- C) リポジトリ全体
- D) インターネット上のすべてのコード

<details>
<summary>解答</summary>
B) 現在のファイルとIDE内の他の開いているファイル/タブ - LLMは、現在のファイルだけでなく、IDE内の他の開いているファイルやタブも考慮して、正確で関連するコード補完を生成します。
</details>

**Q3. LLMの微調整において「ソースモデル」とは何を指しますか？**
- A) ユーザーが作成したカスタムモデル
- B) 大規模な事前トレーニング済みデータセットから得られた知識とパラメーター
- C) タスク固有の小さなデータセット
- D) GitHubのプライベートリポジトリ

<details>
<summary>解答</summary>
B) 大規模な事前トレーニング済みデータセットから得られた知識とパラメーター - 微調整では、ソースモデルと呼ばれる大規模な事前トレーニング済みデータセットから得られた知識とパラメーターを使用します。
</details>

**Q4. LoRA（低ランク適応）の主な利点として正しいものは？**
- A) すべてのニューラルネットワーク層を再トレーニングする
- B) 元のモデルを完全に置き換える
- C) 元のモデルを変更せず、小さなトレーニング可能パーツを追加して時間とリソースを節約
- D) モデルサイズを10倍に拡大する

<details>
<summary>解答</summary>
C) 元のモデルを変更せず、小さなトレーニング可能パーツを追加して時間とリソースを節約 - LoRAでは、元のモデルは同じままであるため、時間とリソースが節約されます。
</details>

**Q5. LLMの「汎用性」として正しい説明は？**
- A) 特定のプログラミング言語のみに対応
- B) 英語のテキストのみを処理可能
- C) 特定の種類のテキストや言語に限定されず、様々な分野に適用可能
- D) コード生成のみに特化している

<details>
<summary>解答</summary>
C) 特定の種類のテキストや言語に限定されず、様々な分野に適用可能 - LLMは特定の種類のテキストや言語に限定されず、特殊なタスクを実行するように調整および微調整することができ、汎用性が高く、さまざまな分野や言語に適用できます。
</details>

**Q6. 大規模言語モデル (LLM) の微調整のコンテキストでの LoRA とは何ですか?**
- A) 完全な見直しを行わずに、事前トレーニング済みモデルの各レイヤーにトレーニング可能な要素を追加するメソッド
- B) 異なるコーディング言語間の通信を最適化するテクノロジ
- C) Copilot のパフォーマンスを向上させる特殊なソフトウェア ライブラリ
- D) Copilot によって排他的にサポートされる新しいプログラミング パラダイム

<details>
<summary>解答</summary>
A) 完全な見直しを行わずに、事前トレーニング済みモデルの各レイヤーにトレーニング可能な要素を追加するメソッド - LoRA（Low-Rank Adaptation）は、事前トレーニング済みモデルの各レイヤーに小さなトレーニング可能なパーツを追加し、元のモデルを変更せずに微調整を行う効率的な方法です。
</details>

---

## 追加小テスト: プロンプトエンジニアリング認定試験対策（類似問題）

### 問題1
GitHub Copilotの出力品質を決定する主な要因は何ですか？

- A) コンピューターの処理速度
- B) インターネット接続の帯域幅
- C) プロンプトの明確さと提供されるコンテキストの質
- D) IDEのバージョン

<details>
<summary>解答</summary>

**正解: C) プロンプトの明確さと提供されるコンテキストの質**

GitHub Copilotの出力品質は、ユーザーが提供するプロンプトの明確さとコンテキストの質に大きく依存します。具体的で詳細なプロンプトと適切なコンテキストを提供することで、より関連性の高い正確な提案を得ることができます。

</details>

---

### 問題2
効果的でないプロンプトエンジニアリングの原則はどれですか？

- A) 明確で具体的な指示を提供する
- B) 関連するコード例を含める
- C) できるだけ曖昧で一般的なプロンプトを使用する
- D) タスクを小さな部分に分割する

<details>
<summary>解答</summary>

**正解: C) できるだけ曖昧で一般的なプロンプトを使用する**

曖昧で一般的なプロンプトは、GitHub Copilotから有用な応答を得る可能性を低下させます。効果的なプロンプトエンジニアリングでは、明確で具体的な指示、関連する例、適切なコンテキストの提供が重要です。

</details>

---

### 問題3
GitHub Copilot Chatのパフォーマンスを向上させるためのベストプラクティスとして正しいものはどれですか？

- A) できるだけ長い複雑なプロンプトを書く
- B) 複雑な問題を小さく焦点を絞ったクエリに分割する
- C) コンテキストを提供せずに質問する
- D) 同じ質問を何度も繰り返す

<details>
<summary>解答</summary>

**正解: B) 複雑な問題を小さく焦点を絞ったクエリに分割する**

LLMのコンテキストウィンドウには制限があるため、複雑な問題を小さく焦点を絞ったクエリに分割し、関連するコードスニペットを提供することで、モデルの正確性と有用性を向上させることができます。

</details>

---

### 問題4
ゼロショット学習とフューショット学習の違いについて正しい説明はどれですか？

- A) ゼロショットは複数の例を使用し、フューショットは例を使用しない
- B) ゼロショットは例なしでタスクを実行し、フューショットは1つ以上の例を提供してパターン認識を支援する
- C) 両方とも同じ手法で違いはない
- D) ゼロショットは高速で、フューショットは低速である

<details>
<summary>解答</summary>

**正解: B) ゼロショットは例なしでタスクを実行し、フューショットは1つ以上の例を提供してパターン認識を支援する**

ゼロショット学習では具体的な例なしでコード生成を行います。一方、フューショット学習（ワンショットや少数ショット）では、1つ以上の例を提供してモデルのパターン認識を支援し、より正確な結果を得ることができます。

</details>

---

### 問題5
プロンプトでコンテキストと意図を明確にすることの重要性について正しい説明はどれですか？

- A) コンテキストは必要なく、短いプロンプトが最も効果的である
- B) 適切なコンテキストを提供することで、GitHub Copilotはより正確で関連性の高い提案を生成できる
- C) 意図は自動的に推測されるため、明示する必要はない
- D) コンテキストを多く提供すると混乱を招く

<details>
<summary>解答</summary>

**正解: B) 適切なコンテキストを提供することで、GitHub Copilotはより正確で関連性の高い提案を生成できる**

コンテキストと意図を明確にすることで、GitHub Copilotはユーザーが達成しようとしていることをより良く理解し、より正確で関連性の高いコード提案を生成することができます。これは4つのSの「周囲環境（Surround）」原則にも関連しています。

</details>

---

### 問題6
プロンプトからの学習についての説明で正しいものはどれですか？

- A) GitHub Copilotはすべてのユーザープロンプトからリアルタイムで学習する
- B) プロンプトはセッション中のコンテキストとして使用され、適切な応答を生成するのに役立つ
- C) プロンプトは他のユーザーと自動的に共有される
- D) プロンプトは外部データベースに永続的に保存される

<details>
<summary>解答</summary>

**正解: B) プロンプトはセッション中のコンテキストとして使用され、適切な応答を生成するのに役立つ**

GitHub Copilotは、プロンプトをセッション中のコンテキストとして使用して適切な応答を生成します。チャット履歴を通じて会話のコンテキストを保持しますが、リアルタイムでモデルを再トレーニングするわけではありません。

</details>

---

### 問題7
コンテキストを提供するための最善の方法として正しいものはどれですか？

- A) 関連するファイルをすべて閉じて、現在のファイルのみに集中する
- B) 関連するファイルを開いておき、明確なファイル名と適切なコメントを使用する
- C) コードのコメントをすべて削除する
- D) 大量の無関係なファイルを開いておく

<details>
<summary>解答</summary>

**正解: B) 関連するファイルを開いておき、明確なファイル名と適切なコメントを使用する**

GitHub Copilotは、開いているファイル、ファイル名、コード内のコメントなどからコンテキストを収集します。関連するファイルを開いておき、明確でわかりやすいファイル名を使用し、適切なコメントを含めることで、より良い提案を得ることができます。これは4つのSの「周囲環境（Surround）」原則に該当します。

</details>
