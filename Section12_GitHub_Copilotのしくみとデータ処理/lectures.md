# セクション12: GitHub Copilotのしくみとデータ処理（15%）

## レクチャー1: コード提案のデータパイプラインライフサイクル
**時間目安: 12分**

（内容を記述）

---

## レクチャー2: コンテキスト収集とプロンプト構築の仕組み
**時間目安: 12分**

（内容を記述）

---

## レクチャー3: プロキシサービスとフィルター処理
**時間目安: 10分**

（内容を記述）

---

## レクチャー4: 大規模言語モデル（LLM）のレスポンス生成
**時間目安: 10分**

（内容を記述）

---

## レクチャー5: 一致コード識別と後処理
**時間目安: 10分**

（内容を記述）

---

## レクチャー6: データフロー（Individual/Chat/コード補完）
**時間目安: 12分**

（内容を記述）

---

## レクチャー7: LLMの制限（コンテキストウィンドウ・データの古さ）
**時間目安: 10分**

（内容を記述）

---

## 確認テスト: GitHub Copilotのしくみとデータ処理

### 問題1
GitHub Copilotがコード補完候補を生成するために主に使用しているものは何ですか？

- A) ルールベースのパターンマッチング
- B) 大規模言語モデル（LLM）
- C) データベースクエリ
- D) 静的コード解析のみ

<details>
<summary>解答</summary>

**正解: B) 大規模言語モデル（LLM）**

GitHub Copilotは大規模言語モデル（LLM）を使用してコード補完候補を生成します。LLMは膨大なコードデータでトレーニングされており、コンテキストを理解して適切なコード提案を行います。

</details>

---

### 問題2
GitHub Copilotの処理プロセスに含まれないステップはどれですか？

- A) コンテキストの収集とプロンプトの構築
- B) LLMによる提案の生成
- C) ユーザーのコードをトレーニングデータとして保存
- D) フィルター処理と後処理

<details>
<summary>解答</summary>

**正解: C) ユーザーのコードをトレーニングデータとして保存**

GitHub Copilotの処理プロセスには、コンテキスト収集、プロンプト構築、LLMによる提案生成、フィルター処理が含まれます。ただし、GitHub Copilot for Businessでは、ユーザーのコードをAIモデルのトレーニングデータとして保存または使用しません。

</details>

---

### 問題3
Fill-in-the-Middle（FIM）手法について正しい説明はどれですか？

- A) ファイルの最初の部分のみを読み取る
- B) カーソルの前後のコンテキストを使用して、より適切な提案を生成する
- C) 外部ファイルのみを参照する
- D) コードを削除する技術

<details>
<summary>解答</summary>

**正解: B) カーソルの前後のコンテキストを使用して、より適切な提案を生成する**

Fill-in-the-Middle（FIM）手法では、カーソルの前のコード（プレフィックス）と後のコード（サフィックス）の両方をコンテキストとして使用します。これにより、既存のコード構造に適合する、より正確で関連性の高い提案が可能になります。

</details>

---

### 問題4
GitHub Copilotが提案を生成した後に行われる処理として正しいものはどれですか？

- A) 提案をそのまま表示する
- B) 一致コードの識別、フィルタリング、ユーザーへの表示
- C) 提案を永続的に保存する
- D) 自動的にコードをコミットする

<details>
<summary>解答</summary>

**正解: B) 一致コードの識別、フィルタリング、ユーザーへの表示**

LLMが提案を生成した後、GitHub Copilotは一致コードの識別（パブリックコードとの照合）、不適切なコンテンツのフィルタリング、そしてユーザーへの提案表示という処理を行います。

</details>

---

### 問題5
LLMのコンテキストウィンドウに関する制限として正しいものはどれですか？

- A) 制限なく無限のコードを処理できる
- B) 一度に処理できるトークン数に制限があり、大きなファイルすべてを理解することは困難
- C) テキストのみを処理でき、コードは処理できない
- D) 英語のみを処理できる

<details>
<summary>解答</summary>

**正解: B) 一度に処理できるトークン数に制限があり、大きなファイルすべてを理解することは困難**

LLMにはコンテキストウィンドウという制限があり、一度に処理できるトークン（単語やコードの断片）の数に上限があります。そのため、非常に大きなファイルやプロジェクト全体のすべてのコンテキストを一度に理解することは困難です。

</details>

---

### 問題6
GitHub Copilotのプロキシサービスの役割として正しくないものはどれですか？

- A) ユーザーからのリクエストを受け取る
- B) LLMへのリクエストを転送する
- C) ユーザーのコードを永続的に保存する
- D) フィルタリングと後処理を行う

<details>
<summary>解答</summary>

**正解: C) ユーザーのコードを永続的に保存する**

GitHub Copilotのプロキシサービスは、ユーザーからのリクエスト受信、LLMへの転送、レスポンスのフィルタリングと後処理を担当します。ただし、ユーザーのコードを永続的に保存することはありません（特にBusinessプランでは、プロンプトや提案は保持されません）。

</details>
