---
marp: true
theme: custom-theme
paginate: true
---

<!-- _class: title -->
<!-- _paginate: false -->

# 責任あるAI

---

# 学習目標

このセクションでは以下の内容を学習します。

- AIの使用に関連する**リスクと制限事項**を理解する
- **責任あるAIの6つの原則**を説明できる
- 各原則の**実装方法**と**具体例**を理解する
- 試験で問われるポイントを押さえる

<span class="red">試験ポイント: 6つの原則の名称と内容を正確に覚えましょう</span>
<span class="red">公平性、信頼性と安全性、プライバシーとセキュリティ、包括性、透明性、説明責任</span>

---

<!-- _class: lecture -->
<!-- _paginate: false -->

# AIに関連するリスクと制限事項

---

# AIがもたらすリスク

AIは多くの効率化や革新をもたらす一方で、慎重に管理すべき**重大なリスク**を伴います。

## 主な懸念事項

| 懸念事項 | 具体的な問題 |
|----------|-------------|
| **透明性と説明責任の欠如** | AIシステムが解釈困難な意思決定を行う可能性 |
| **意図しない有害な結果** | 偏った意思決定、プライバシーの侵害 |

<span class="red">試験ポイント: AIは便利なだけでなく、リスクも伴うことを理解する</span>

---

# リスク軽減のための対策

AIのリスクを最小限に抑えるためには、以下の実装が不可欠です：

| 対策 | 説明 |
|------|------|
| **堅牢なガバナンスフレームワーク** | AIの使用に関するルールと監視体制を整備 |
| **AIプロセスの透明性確保** | 意思決定の過程を明確にする |
| **人による監視の組み込み** | 最終判断には人間が関与する |

**目標**: 組織がAIの利点を活用しながら、潜在的な悪影響を最小限に抑えること

<span class="red">試験ポイント: 「人による監視の排除」は誤り！人の監視は必須です</span>

---

# 「責任あるAI」とは？

## 定義

> 安全で信頼でき、倫理的な方法でAIシステムを開発、評価、デプロイするためのアプローチ

## 主要な価値

人とその目標をシステム設計の中心に置き、以下の価値を尊重します：

- **公平性** - すべてのユーザーを平等に扱う
- **信頼性** - 安全で予測可能な動作
- **透明性** - 理解可能で説明可能

---

# 責任あるAIの6つの原則

MicrosoftとGitHubが定める責任あるAIの6つの原則：

| # | 原則 | 英語名 |
|---|------|--------|
| 1 | **公平性** | Fairness |
| 2 | **信頼性と安全性** | Reliability and Safety |
| 3 | **プライバシーとセキュリティ** | Privacy and Security |
| 4 | **包括性** | Inclusivity |
| 5 | **透明性** | Transparency |
| 6 | **説明責任** | Accountability |

<span class="red">試験ポイント: 6つの原則とその内容を覚えましょう！</span>

---

<!-- _class: lecture -->
<!-- _paginate: false -->

# 責任あるAIの原則①「公平性」

---

# 公平性（Fairness）

## 定義

**AIシステムはすべてのユーザーを公平に扱う必要があります**

## なぜ重要か？

AIが特定のグループに対して不利な判断をすると、差別的な結果を生む可能性があります。

例：
- ローン審査で特定の人種に不利な判定
- 採用システムで特定の性別を排除
- 医療診断で特定の年齢層の精度が低い

---

# 公平性の実装方法

| 実装方法 | 説明 |
|----------|------|
| **トレーニングデータの確認** | 偏りのないデータセットを使用 |
| **バランスの取れたテスト** | 多様な人口統計サンプルでモデルをテスト |
| **敵対的デバイアス** | バイアスを検出・除去する技術を使用 |
| **パフォーマンス監視** | ユーザーセグメント全体での動作を監視 |
| **オーバーライド制御** | 不公平なスコアを上書きする仕組み |

<span class="red">試験ポイント: 「単一のグループのデータのみでトレーニング」は公平性に反します</span>

---

# 公平性の応用例

## 具体的なシナリオ

- **医療**: 患者の人種や性別に関わらず、同じ症状には同じ診断を推奨
- **ローン申請**: 同じ信用状況なら、同じ審査結果を提供
- **雇用**: 同じスキルと経験を持つ候補者に、同等の評価を与える

## 公平性を確保するためのチェックリスト

- [ ] トレーニングデータに偏りはないか？
- [ ] 異なるグループで同等のパフォーマンスか？
- [ ] バイアスを検出する仕組みがあるか？

---

<!-- _class: lecture -->
<!-- _paginate: false -->

# 責任あるAIの原則②「信頼性と安全性」

---

# 信頼性と安全性（Reliability and Safety）

## 定義

**AIシステムは確実かつ安全に実行される必要があります**

## 2つの重要概念

| 概念 | 説明 |
|------|------|
| **安全性** | 個人や社会への物理的、感情的、経済的損害を最小限に抑えること |
| **信頼性** | 望ましくないばらつきやエラーを発生させず、意図したとおりに一貫して動作すること |

<span class="red">試験ポイント: 安全性と信頼性の違いを理解しましょう</span>

---

# 信頼性と安全性の要件

## 必要な特性

| 要件 | 説明 |
|------|------|
| **堅牢性** | 異常な入力や状況でも適切に動作する |
| **正確性** | 正しい結果を高い精度で出力する |
| **予測可能性** | 正常な条件下で一貫した動作をする |

## 実装のポイント

- 十分なテストと検証を行う
- エッジケース（例外的なケース）を考慮する
- 障害時の安全な動作（フェイルセーフ）を設計する

---

<!-- _class: lecture -->
<!-- _paginate: false -->

# 責任あるAIの原則③「プライバシーとセキュリティ」

---

# プライバシーとセキュリティ（Privacy and Security）

## 定義

**AIシステムは安全でプライバシーを尊重する必要があります**

## データ収集の原則

| 原則 | 説明 |
|------|------|
| **同意を得る** | 使用前にユーザーの許可を得る |
| **最小限のデータ** | 必要なデータのみ収集する |
| **匿名化** | 個人データを仮名化、集約などで保護 |

<span class="red">試験ポイント: 「すべてのユーザーデータを無期限に保存」はNG！</span>

---

# データ保護の方法

## 技術的な対策

| 対策 | 説明 |
|------|------|
| **暗号化** | 転送中および格納時にデータを暗号化 |
| **HSM** | ハードウェアセキュリティモジュールの使用 |
| **セキュアなコンテナー** | Azureなどのセキュアな環境を利用 |
| **エンベロープ暗号化** | 鍵を別の鍵で暗号化する方式 |
| **キーローテーション** | 定期的に暗号鍵を更新 |

---

# プライバシーとセキュリティの運用

## 組織的な対策

| 対策 | 説明 |
|------|------|
| **アクセス制限** | 従業員のデータアクセスを必要最小限に |
| **セキュリティ監査** | 定期的に脆弱性をチェック |
| **インシデント対応** | 問題発生時の対応手順を整備 |

## ベストプラクティス

- データを暗号化せずに保存しない
- すべての従業員に無制限アクセスを許可しない
- セキュリティ監査を省略しない

---

<!-- _class: lecture -->
<!-- _paginate: false -->

# 責任あるAIの原則④「包括性」

---

# 包括性（Inclusivity）

## 定義

**AIシステムはすべてのユーザーを支援し、ユーザーを関与させる必要があります**

## 実装要件

- 多様なユーザーやグループに対して適切に機能
- アクセスしやすさの確保（身体的・精神的能力に関わらず）
- 全世界での利用可能性
- 多様なバックグラウンドの人々による開発への参加
- すべてのユーザーが平等に機能から恩恵を受けること

---

# 包括性の実装例

## 具体的な実装

| カテゴリ | 例 |
|----------|-----|
| **多様性への対応** | 肌の色、年齢、性別に関わらず機能する顔認識 |
| **アクセシビリティ** | 視覚障碍者向けのスクリーンリーダー対応 |
| **地域対応** | 地域言語サポート |
| **開発チーム** | 多様な観点を持つチーム編成 |

<span class="red">試験ポイント: 「特定のユーザーグループのみを対象に開発」は包括性に反します</span>

---

# グローバル包括の実現方法

## 代替対話モードの提供

- **音声コントロール** - 手が使えない人のために
- **字幕** - 聴覚障碍者のために
- **スクリーンリーダー** - 視覚障碍者のために

## その他の対応

| 対応 | 説明 |
|------|------|
| **言語・文化への適応** | 異なる言語・地域文化に対応 |
| **オフライン動作** | 限られた接続環境でも動作 |
| **低スペック対応** | 高性能でないデバイスでも使用可能 |

---

<!-- _class: lecture -->
<!-- _paginate: false -->

# 責任あるAIの原則⑤「透明性」

---

# 透明性（Transparency）

## 定義

**AIシステムは理解可能かつ解釈可能である必要があります**

## AI作成者の責務

| 責務 | 説明 |
|------|------|
| **動作の説明** | 明確な検証フレームワークでシステム動作を説明 |
| **設計の正当化** | 設計選択の理由を示す |
| **正直な情報提供** | 機能と制限について正直に伝える |
| **監査機能** | ログ、レポート、監査機能を使用 |

<span class="red">試験ポイント: 「機能と制限を隠す」は透明性に反します！</span>

---

# 透明性の実装方法

## 具体的な手法

| 手法 | 説明 |
|------|------|
| **ドキュメント化** | データとモデルの詳細を記録 |
| **わかりやすいUI** | ユーザーが理解しやすいインターフェイス |
| **デバッグツール** | AIの動作を検証するツール |
| **テストダッシュボード** | テスト結果を可視化 |
| **ログと監査** | 動作履歴を記録・追跡可能に |

---

# 透明性がもたらす効果

透明性を確保することで、以下の効果が得られます：

| 効果 | 説明 |
|------|------|
| **信頼構築** | ユーザーがAIを信頼できる |
| **説明責任確保** | 問題発生時に原因を追跡できる |
| **公平性促進** | バイアスを発見・修正できる |
| **安全性強化** | 問題を早期に発見できる |
| **包括性サポート** | 多様なユーザーのニーズを理解できる |

---

<!-- _class: lecture -->
<!-- _paginate: false -->

# 責任あるAIの原則⑥「説明責任」

---

# 説明責任（Accountability）

## 定義

**すべてのユーザーがAIシステムに責任を負います**

## 誰が責任を負うのか？

| 役割 | 責任 |
|------|------|
| **AI作成者** | システム動作に対して責任を負う |
| **展開企業** | 運用に責任を持つ |
| **すべての関係者** | AIの出力と影響に責任を持つ |

<span class="red">試験ポイント: 「誰も責任を負わない」は誤り！作成者も展開企業も責任があります</span>

---

# 説明責任の要件

## 必要なアクション

| 要件 | 説明 |
|------|------|
| **継続的監視** | パフォーマンスを常にチェック |
| **リスク軽減** | 問題を発見したら迅速に対応 |
| **是正措置** | 問題が発生したら修正する |

## なぜ重要か？

アルゴリズムによる損害、偏り、不正使用などの問題に対応するために不可欠

---

# Microsoftの説明責任に対する立場

## Microsoftの見解

- AIシステムは**ユーザーに説明責任を負う**
- 展開企業は**運用に責任を持つ必要がある**

## 責任の連鎖

| 開発者 | ➡️ | 提供企業 | ➡️ | 展開企業 | ➡️ | ユーザー |
|:------:|:--:|:--------:|:--:|:--------:|:--:|:--------:|
| ⬇️ | | ⬇️ | | ⬇️ | | ⬇️ |
| **設計責任** | | **製品責任** | | **運用責任** | | **利用責任** |

すべての関係者が、それぞれの立場で責任を持つことが重要です。

---

# セクションまとめ

## 責任あるAIの6つの原則

| 原則 | キーポイント |
|------|-------------|
| **公平性** | すべてのユーザーを平等に扱う |
| **信頼性と安全性** | 一貫した動作と損害の最小化 |
| **プライバシーとセキュリティ** | データ保護と暗号化 |
| **包括性** | 多様なユーザーへの対応 |
| **透明性** | 理解可能で説明可能 |
| **説明責任** | すべての関係者が責任を持つ |

---

# 試験対策ポイント

## よく出る間違い選択肢

| ❌ 間違い | ✅ 正解 |
|----------|---------|
| 人による監視の排除 | 人による監視の組み込み |
| データを無期限保存 | 必要最小限の期間のみ保存 |
| 機能と制限を隠す | 機能と制限を公開する |
| 誰も責任を負わない | 全関係者が責任を持つ |
| 収益性が原則に含まれる | 収益性は原則に含まれない |

<span class="red">これらの「間違い選択肢」を覚えておくと、試験で役立ちます！</span>